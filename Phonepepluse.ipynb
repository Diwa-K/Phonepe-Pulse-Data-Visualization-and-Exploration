{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import streamlit as st\n",
    "import sqlite3\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from streamlit_option_menu import option_menu\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cloning the Data directly from the Github \n",
    "response = requests.get('https://api.github.com/repos/PhonePe/pulse')\n",
    "repo = response.json()\n",
    "clone_url = repo['clone_url']\n",
    "repo_name = \"pulse\"\n",
    "clone_dir = os.path.join(os.getcwd(), repo_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the data as states\n",
    "path = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       State  Year  Quater          Transaction_type  \\\n",
      "0     andaman&nicobarislands  2018       1  Recharge & bill payments   \n",
      "1     andaman&nicobarislands  2018       1     Peer-to-peer payments   \n",
      "2     andaman&nicobarislands  2018       1         Merchant payments   \n",
      "3     andaman&nicobarislands  2018       1        Financial Services   \n",
      "4     andaman&nicobarislands  2018       1                    Others   \n",
      "...                      ...   ...     ...                       ...   \n",
      "4129             west-bengal  2023       3         Merchant payments   \n",
      "4130             west-bengal  2023       3     Peer-to-peer payments   \n",
      "4131             west-bengal  2023       3  Recharge & bill payments   \n",
      "4132             west-bengal  2023       3        Financial Services   \n",
      "4133             west-bengal  2023       3                    Others   \n",
      "\n",
      "      Transaction_count  Transaction_amount  \n",
      "0                  4200        1.845307e+06  \n",
      "1                  1871        1.213866e+07  \n",
      "2                   298        4.525072e+05  \n",
      "3                    33        1.060142e+04  \n",
      "4                   256        1.846899e+05  \n",
      "...                 ...                 ...  \n",
      "4129          296965002        2.004404e+11  \n",
      "4130          271150280        8.310501e+11  \n",
      "4131           63055684        3.920985e+10  \n",
      "4132             389751        4.249856e+08  \n",
      "4133             532474        4.232851e+08  \n",
      "\n",
      "[4134 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "clm = {'State': [], 'Year': [], 'Quater': [], 'Transaction_type': [], 'Transaction_count': [], 'Transaction_amount': []}\n",
    "for i in Agg_state_list:\n",
    "    p_i = path + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            D = json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "                Name = z['name']\n",
    "                count = z['paymentInstruments'][0]['count']\n",
    "                amount = z['paymentInstruments'][0]['amount']\n",
    "                clm['Transaction_type'].append(Name)\n",
    "                clm['Transaction_count'].append(count)\n",
    "                clm['Transaction_amount'].append(amount)\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quater'].append(int(k.strip('.json')))\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_aggregated_transaction = pd.DataFrame(clm)\n",
    "print(df_aggregated_transaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          State  Year  Quater   brands    Count  Percentage\n",
      "0     andaman-&-nicobar-islands  2018       1   Xiaomi     1665    0.247033\n",
      "1     andaman-&-nicobar-islands  2018       1  Samsung     1445    0.214392\n",
      "2     andaman-&-nicobar-islands  2018       1     Vivo      982    0.145697\n",
      "3     andaman-&-nicobar-islands  2018       1     Oppo      501    0.074332\n",
      "4     andaman-&-nicobar-islands  2018       1  OnePlus      332    0.049258\n",
      "...                         ...   ...     ...      ...      ...         ...\n",
      "6727                west-bengal  2022       1   Lenovo   330017    0.015056\n",
      "6728                west-bengal  2022       1  Infinix   284678    0.012987\n",
      "6729                west-bengal  2022       1     Asus   280347    0.012790\n",
      "6730                west-bengal  2022       1    Apple   277752    0.012671\n",
      "6731                west-bengal  2022       1   Others  2196334    0.100199\n",
      "\n",
      "[6732 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "path2 = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/aggregated/user/country/india/state/\"\n",
    "user_list = os.listdir(path2)\n",
    "\n",
    "col2 = {'State': [], 'Year': [], 'Quater': [], 'brands': [], 'Count': [],\n",
    "        'Percentage': []}\n",
    "for i in user_list:\n",
    "    p_i = path2 + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            B = json.load(Data)\n",
    "            try:\n",
    "                for w in B[\"data\"][\"usersByDevice\"]:\n",
    "                    brand_name = w[\"brand\"]\n",
    "                    count_ = w[\"count\"]\n",
    "                    ALL_percentage = w[\"percentage\"]\n",
    "                    col2[\"brands\"].append(brand_name)\n",
    "                    col2[\"Count\"].append(count_)\n",
    "                    col2[\"Percentage\"].append(ALL_percentage)\n",
    "                    col2[\"State\"].append(i)\n",
    "                    col2[\"Year\"].append(j)\n",
    "                    col2[\"Quater\"].append(int(k.strip('.json')))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_aggregated_user = pd.DataFrame(col2)\n",
    "print(df_aggregated_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           State  Year  Quater  \\\n",
      "0      andaman-&-nicobar-islands  2018       1   \n",
      "1      andaman-&-nicobar-islands  2018       1   \n",
      "2      andaman-&-nicobar-islands  2018       1   \n",
      "3      andaman-&-nicobar-islands  2018       2   \n",
      "4      andaman-&-nicobar-islands  2018       2   \n",
      "...                          ...   ...     ...   \n",
      "16827                west-bengal  2023       3   \n",
      "16828                west-bengal  2023       3   \n",
      "16829                west-bengal  2023       3   \n",
      "16830                west-bengal  2023       3   \n",
      "16831                west-bengal  2023       3   \n",
      "\n",
      "                                District     count        amount  \n",
      "0      north and middle andaman district       442  9.316631e+05  \n",
      "1                 south andaman district      5688  1.256025e+07  \n",
      "2                      nicobars district       528  1.139849e+06  \n",
      "3      north and middle andaman district       825  1.317863e+06  \n",
      "4                 south andaman district      9395  2.394824e+07  \n",
      "...                                  ...       ...           ...  \n",
      "16827                     nadia district  30146530  5.787869e+10  \n",
      "16828                   birbhum district  17597047  3.090737e+10  \n",
      "16829           purba medinipur district  34244893  6.813718e+10  \n",
      "16830                    maldah district  28539407  5.299766e+10  \n",
      "16831                 darjiling district  14747572  2.463195e+10  \n",
      "\n",
      "[16832 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the data to create the dataframe as Map (Transaction)\n",
    "\n",
    "path3 = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "hover_list = os.listdir(path3)\n",
    "\n",
    "col3 = {'State': [], 'Year': [], 'Quater': [], 'District': [], 'count': [],\n",
    "        'amount': []}\n",
    "for i in hover_list:\n",
    "    p_i = path3 + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            C = json.load(Data)\n",
    "            for x in C[\"data\"][\"hoverDataList\"]:\n",
    "                District = x[\"name\"]\n",
    "                count = x[\"metric\"][0][\"count\"]\n",
    "                amount = x[\"metric\"][0][\"amount\"]\n",
    "                col3[\"District\"].append(District)\n",
    "                col3[\"count\"].append(count)\n",
    "                col3[\"amount\"].append(amount)\n",
    "                col3['State'].append(i)\n",
    "                col3['Year'].append(j)\n",
    "                col3['Quater'].append(int(k.strip('.json')))\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_map_transaction = pd.DataFrame(col3)\n",
    "print(df_map_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           State  Year  Quater  \\\n",
      "0      andaman-&-nicobar-islands  2018       1   \n",
      "1      andaman-&-nicobar-islands  2018       1   \n",
      "2      andaman-&-nicobar-islands  2018       1   \n",
      "3      andaman-&-nicobar-islands  2018       2   \n",
      "4      andaman-&-nicobar-islands  2018       2   \n",
      "...                          ...   ...     ...   \n",
      "16831                west-bengal  2023       3   \n",
      "16832                west-bengal  2023       3   \n",
      "16833                west-bengal  2023       3   \n",
      "16834                west-bengal  2023       3   \n",
      "16835                west-bengal  2023       3   \n",
      "\n",
      "                                District  RegisteredUser  \n",
      "0      north and middle andaman district             632  \n",
      "1                 south andaman district            5846  \n",
      "2                      nicobars district             262  \n",
      "3      north and middle andaman district             911  \n",
      "4                 south andaman district            8143  \n",
      "...                                  ...             ...  \n",
      "16831                     nadia district         1544294  \n",
      "16832                   birbhum district          974363  \n",
      "16833           purba medinipur district         1530289  \n",
      "16834                    maldah district         1091634  \n",
      "16835                 darjiling district          637665  \n",
      "\n",
      "[16836 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the data to create the dataframe as Map (User)\n",
    "\n",
    "path4 = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_list = os.listdir(path4)\n",
    "\n",
    "col4 = {\"State\": [], \"Year\": [], \"Quater\": [], \"District\": [],\n",
    "        \"RegisteredUser\": []}\n",
    "for i in map_list:\n",
    "    p_i = path4 + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            D = json.load(Data)\n",
    "\n",
    "            for u in D[\"data\"][\"hoverData\"].items():\n",
    "                district = u[0]\n",
    "                registereduser = u[1][\"registeredUsers\"]\n",
    "                col4[\"District\"].append(district)\n",
    "                col4[\"RegisteredUser\"].append(registereduser)\n",
    "                col4['State'].append(i)\n",
    "                col4['Year'].append(j)\n",
    "                col4['Quater'].append(int(k.strip('.json')))\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_map_user = pd.DataFrame(col4)\n",
    "print(df_map_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          State  Year  Quater District  Transaction_count  \\\n",
      "0     andaman-&-nicobar-islands  2018       1   744101               1622   \n",
      "1     andaman-&-nicobar-islands  2018       1   744103               1223   \n",
      "2     andaman-&-nicobar-islands  2018       1   744102                969   \n",
      "3     andaman-&-nicobar-islands  2018       1   744105                685   \n",
      "4     andaman-&-nicobar-islands  2018       1   744104                340   \n",
      "...                         ...   ...     ...      ...                ...   \n",
      "8205                west-bengal  2023       3   700001            3536928   \n",
      "8206                west-bengal  2023       3   721301            3464729   \n",
      "8207                west-bengal  2023       3   700039            3405551   \n",
      "8208                west-bengal  2023       3   732125            3347165   \n",
      "8209                west-bengal  2023       3   700015            3304464   \n",
      "\n",
      "      Transaction_amount  \n",
      "0           2.769298e+06  \n",
      "1           2.238042e+06  \n",
      "2           3.519060e+06  \n",
      "3           1.298561e+06  \n",
      "4           1.039715e+06  \n",
      "...                  ...  \n",
      "8205        7.193522e+09  \n",
      "8206        4.871566e+09  \n",
      "8207        5.095825e+09  \n",
      "8208        5.353831e+09  \n",
      "8209        5.003674e+09  \n",
      "\n",
      "[8210 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extracting the data to create the dataframe as Top (Transaction)\n",
    "\n",
    "path5 = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/top/transaction/country/india/state/\"\n",
    "TOP_list = os.listdir(path5)\n",
    "\n",
    "col5 = {'State': [], 'Year': [], 'Quater': [], 'District': [], 'Transaction_count': [],\n",
    "        'Transaction_amount': []}\n",
    "for i in TOP_list:\n",
    "    p_i = path5 + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            E = json.load(Data)\n",
    "            for z in E['data']['pincodes']:\n",
    "                Name = z['entityName']\n",
    "                count = z['metric']['count']\n",
    "                amount = z['metric']['amount']\n",
    "                col5['District'].append(Name)\n",
    "                col5['Transaction_count'].append(count)\n",
    "                col5['Transaction_amount'].append(amount)\n",
    "                col5['State'].append(i)\n",
    "                col5['Year'].append(j)\n",
    "                col5['Quater'].append(int(k.strip('.json')))\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_top_transaction = pd.DataFrame(col5)\n",
    "print(df_top_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          State  Year  Quater District  RegisteredUser\n",
      "0     andaman-&-nicobar-islands  2018       1   744103            1608\n",
      "1     andaman-&-nicobar-islands  2018       1   744101            1108\n",
      "2     andaman-&-nicobar-islands  2018       1   744105            1075\n",
      "3     andaman-&-nicobar-islands  2018       1   744102            1006\n",
      "4     andaman-&-nicobar-islands  2018       1   744104             272\n",
      "...                         ...   ...     ...      ...             ...\n",
      "8206                west-bengal  2023       3   700015          122316\n",
      "8207                west-bengal  2023       3   742304          119245\n",
      "8208                west-bengal  2023       3   721101          118798\n",
      "8209                west-bengal  2023       3   700150          114987\n",
      "8210                west-bengal  2023       3   734006          113991\n",
      "\n",
      "[8211 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the data to create the dataframe as Top (user)\n",
    "path6 = \"C:/Users/Diwa/Desktop/DS/python/phnpe/pulse/data/top/user/country/india/state/\"\n",
    "USER_list = os.listdir(path6)\n",
    "\n",
    "col6 = {'State': [], 'Year': [], 'Quater': [], 'District': [],\n",
    "        'RegisteredUser': []}\n",
    "for i in USER_list:\n",
    "    p_i = path6 + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            # print(p_k)\n",
    "            Data = open(p_k, 'r')\n",
    "            F = json.load(Data)\n",
    "            for t in F['data']['pincodes']:\n",
    "                Name = t['name']\n",
    "                registeredUser = t['registeredUsers']\n",
    "                col6['District'].append(Name)\n",
    "                col6['RegisteredUser'].append(registeredUser)\n",
    "                col6['State'].append(i)\n",
    "                col6['Year'].append(j)\n",
    "                col6['Quater'].append(int(k.strip('.json')))\n",
    "\n",
    "# CReated Dataframe Successfully\n",
    "df_top_user = pd.DataFrame(col6)\n",
    "print(df_top_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checking for missing and null values:\n",
    "\n",
    "# df_aggregated_transaction.info()\n",
    "# df_aggregated_user.info()\n",
    "# df_map_transaction.info()\n",
    "# df_map_user.info()\n",
    "# df_top_transaction.info()\n",
    "# df_top_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x000001C93FF97F10>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to the MySQL server\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"\", \n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "mycursor = mydb.cursor(buffered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new database and use\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE phonepe_pulse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n"
     ]
    }
   ],
   "source": [
    "# Connect to the new created database\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://root:@localhost/phonepe_pulse', echo=False)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connected to the database successfully!\")\n",
    "\n",
    "except OperationalError as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "df_aggregated_transaction.to_sql('aggregated_transaction', engine, if_exists = 'replace', index=False,   \n",
    "                                 dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                       'Year': sqlalchemy.types.Integer, \n",
    "                                       'Quater': sqlalchemy.types.Integer, \n",
    "                                       'Transaction_type': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                       'Transaction_count': sqlalchemy.types.Integer,\n",
    "                                       'Transaction_amount': sqlalchemy.types.FLOAT(precision=5, asdecimal=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "df_aggregated_user.to_sql('aggregated_user', engine, if_exists = 'replace', index=False,\n",
    "                          dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                 'Year': sqlalchemy.types.Integer, \n",
    "                                 'Quater': sqlalchemy.types.Integer,\n",
    "                                 'Brands': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                 'User_Count': sqlalchemy.types.Integer, \n",
    "                                 'User_Percentage': sqlalchemy.types.FLOAT(precision=5, asdecimal=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3                       \n",
    "df_map_transaction.to_sql('map_transaction', engine, if_exists = 'replace', index=False,\n",
    "                          dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                 'Year': sqlalchemy.types.Integer, \n",
    "                                 'Quater': sqlalchemy.types.Integer, \n",
    "                                 'District': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                 'Transaction_Count': sqlalchemy.types.Integer, \n",
    "                                 'Transaction_Amount': sqlalchemy.types.FLOAT(precision=5, asdecimal=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "df_map_user.to_sql('map_user', engine, if_exists = 'replace', index=False,\n",
    "                   dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                          'Year': sqlalchemy.types.Integer, \n",
    "                          'Quater': sqlalchemy.types.Integer, \n",
    "                          'District': sqlalchemy.types.VARCHAR(length=50), \n",
    "                          'Registered_User': sqlalchemy.types.Integer, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5                  \n",
    "df_top_transaction.to_sql('top_transaction', engine, if_exists = 'replace', index=False,\n",
    "                         dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                                'Year': sqlalchemy.types.Integer, \n",
    "                                'Quater': sqlalchemy.types.Integer,   \n",
    "                                'District_Pincode': sqlalchemy.types.Integer,\n",
    "                                'Transaction_count': sqlalchemy.types.Integer, \n",
    "                                'Transaction_amount': sqlalchemy.types.FLOAT(precision=5, asdecimal=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "df_top_user.to_sql('top_user', engine, if_exists = 'replace', index=False,\n",
    "                   dtype={'State': sqlalchemy.types.VARCHAR(length=50), \n",
    "                          'Year': sqlalchemy.types.Integer, \n",
    "                          'Quater': sqlalchemy.types.Integer,                           \n",
    "                          'District_Pincode': sqlalchemy.types.Integer, \n",
    "                          'Registered_User': sqlalchemy.types.Integer,})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
